{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadbeatmap(beatmap, num_beats, num_chunks_per_beat=8):\n",
    "    if beatmap[len(beatmap)-5:len(beatmap)] != \".json\":\n",
    "        print(\"Beatmap file \" + audio + \" is not of type .json\")\n",
    "        return -1\n",
    "    \n",
    "    with open(beatmap) as f:\n",
    "        data = json.load(f)\n",
    "  \n",
    "    notes = \"_notes\"\n",
    "    time = \"_time\"\n",
    "    line_index = \"_lineIndex\" #column number\n",
    "    line_layer = \"_lineLayer\" #row number\n",
    "    note_color = \"_type\" #0 is one color and 1 is the other\n",
    "    cut_direction = \"_cutDirection\"#9 cut directions\n",
    "\n",
    "    dim_0 = num_beats * num_chunks_per_beat\n",
    "    \n",
    "    # number of rows and columns in the playfield\n",
    "    # number of cells in the playfield (each cell can hold at most 1 note)\n",
    "    playfield_rows = 3\n",
    "    playfield_cols = 4\n",
    "    playfield_cell_count = playfield_rows * playfield_cols\n",
    "    \n",
    "    # number of colors (2): red, blue (order unknown)\n",
    "    # number of directions notes can face (9): \n",
    "    # up, down, left, right, up-left, up-right, down-left, down-right, dot (order unknown)\n",
    "    note_color_count = 2\n",
    "    note_direction_count = 9\n",
    "    \n",
    "    # dimensions for a 'one-hot' representation of a single time unit (chunk)\n",
    "    dim_1 = playfield_rows\n",
    "    dim_2 = playfield_cols\n",
    "    dim_3 = (note_color_count + 1) + (note_direction_count + 1)\n",
    "    \n",
    "    # initialize matrix to zeros, then set the \"no note\" bit for each block at each timestep to 1\n",
    "    outMatrix = np.zeros(shape=(dim_0, dim_1, dim_2, dim_3))\n",
    "    outMatrix[:,:,:,0] = 1\n",
    "    outMatrix[:,:,:,3] = 1\n",
    "    \n",
    "\n",
    "    # for every note in the beatmap, set the color and direction bits for the proper cell to 1\n",
    "    for n in range(len(data[notes])):\n",
    "        entry = int(np.round(data[notes][n][time]*num_chunks_per_beat)) #convert time to row index by rounding to nearest 1/8 beat\n",
    "        if data[notes][n][note_color] < 2:\n",
    "            outMatrix[entry] \\\n",
    "                     [data[notes][n][line_layer]] \\\n",
    "                     [data[notes][n][line_index]] \\\n",
    "                     [data[notes][n][note_color]+1] = 1\n",
    "            outMatrix[entry] \\\n",
    "                     [data[notes][n][line_layer]] \\\n",
    "                     [data[notes][n][line_index]] \\\n",
    "                     [0] = 0\n",
    "            outMatrix[entry] \\\n",
    "                     [data[notes][n][line_layer]] \\\n",
    "                     [data[notes][n][line_index]] \\\n",
    "                     [data[notes][n][cut_direction]+4] = 1\n",
    "            outMatrix[entry] \\\n",
    "                     [data[notes][n][line_layer]] \\\n",
    "                     [data[notes][n][line_index]] \\\n",
    "                     [3] = 0\n",
    "\n",
    "    return outMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_center(x): \n",
    "    return (x - np.apply_along_axis(np.mean, 0, x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadsong(audio, samples_per_chunk=300, num_chunks_per_slice=65, num_chunks_per_beat=8, verbose=0):\n",
    "    if audio[len(audio)-4:len(audio)] != \".ogg\":\n",
    "        print(\"Audio file \" + audio + \" is not of type .ogg\")\n",
    "        return -1\n",
    "    \n",
    "    y, sr = librosa.load(audio)\n",
    "    \n",
    "    song_length = librosa.get_duration(y=y,sr=sr) / 60.0\n",
    "    tempo = np.round(librosa.beat.tempo(y, sr=sr))\n",
    "    new_sample_rate = (tempo/200)*8000\n",
    "    \n",
    "    y = librosa.resample(y, sr, new_sample_rate)\n",
    "    \n",
    "    number_of_beats = int(tempo * song_length)\n",
    "    \n",
    "    return y[0:(len(y)//(samples_per_chunk*num_chunks_per_beat)*(samples_per_chunk*num_chunks_per_beat))], new_sample_rate, number_of_beats, tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_song(song, sample_per_chunk = 300):\n",
    "    song_y = song.reshape(len(song)//300,300)\n",
    "    song_fft = np.abs(np.apply_along_axis(np.fft.fft, 1, song_y))[:,0:(int)(samples_per_chunk/2)+1]\n",
    "    song_fft_mc = np.apply_along_axis(mean_center, 0, song_fft)\n",
    "    return song_fft_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_song(init_song, init_beatmap, song_filepath, beatmap_filepath, num_chunks_per_beat = 8, num_beats_per_sequence = 32):\n",
    "    num_chunks_per_sequence = num_chunks_per_beat * num_beats_per_sequence\n",
    "    \n",
    "    loaded_song_y, loaded_song_sr, num_beats, tempo = loadsong(song_filepath)\n",
    "    \n",
    "    prepped_song = prep_song(loaded_song_y)\n",
    "    \n",
    "    loaded_beatmap = loadbeatmap(beatmap_filepath, num_beats)\n",
    "    \n",
    "    if init_song == None and init_beatmap == None:\n",
    "        init_song = []\n",
    "        init_beatmap = []\n",
    "        \n",
    "    for i in range(num_beats*num_chunks_per_beat-num_chunks_per_sequence):\n",
    "        init_song.append(prepped_song[i:i+num_chunks_per_sequence]) \n",
    "    for i in range(num_beats*num_chunks_per_beat-num_chunks_per_sequence):\n",
    "        init_beatmap.append(loaded_beatmap[i:i+num_chunks_per_sequence]) \n",
    "    \n",
    "    init_song = np.array(init_song)\n",
    "    init_beatmap = np.array(init_beatmap)\n",
    "        \n",
    "    return init_song, init_beatmap, tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(song_list, beatmap_list):\n",
    "    X, Y, tempo = append_song(None, None, song_list[0], beatmap_list[0])\n",
    "    for x, y in zip(song_list[1:], beatmap_list[1:]):\n",
    "        X, Y, tempo = append_song(X, Y, x, y)\n",
    "    \n",
    "    return X, Y, tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_to_max(note_cell):\n",
    "    output = []\n",
    "    output.append(np.argmax(note_cell[:3]))\n",
    "    output.append(np.argmax(note_cell[3:]))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thanks to @shouldsee from https://github.com/mpld3/mpld3/issues/434#issuecomment-340255689\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "            np.int16, np.int32, np.int64, np.uint8,\n",
    "            np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "            np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj,(np.ndarray,)): #### This is the fix\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_beatmap_array(nn_out, division = 4):\n",
    "    original_size = nn_out.shape[0]\n",
    "    sequence_size = nn_out.shape[1]\n",
    "    target_size = nn_out.shape[1] + nn_out.shape[0]\n",
    "\n",
    "    slice_start = (sequence_size * (division - 1) // (division * 2))\n",
    "    slice_end = sequence_size * (division + 1) // (division * 2)\n",
    "    slice_size = slice_end - slice_start\n",
    "    \n",
    "    beatmap = np.zeros(shape=(target_size,3,4,13), dtype = float)\n",
    "    #first section of the beatmap array\n",
    "    beatmap[0:slice_end] = nn_out[0, 0:slice_end,:,:,:]\n",
    "    \n",
    "    #middle section\n",
    "    i = slice_size\n",
    "    while i < original_size:\n",
    "        beatmap[i+slice_start:i+slice_end] = nn_out[i, slice_start:slice_end,:,:,:]\n",
    "        i+=slice_size\n",
    "    \n",
    "    #final section \n",
    "    final_start_index = -(original_size - (i - slice_size))\n",
    "    print(final_start_index)\n",
    "    \n",
    "    beatmap[final_start_index:target_size] = nn_out[original_size-1, final_start_index:sequence_size,:,:,:]\n",
    "    \n",
    "    return beatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_json(original_beatmap, bpm, chunks_per_beat = 8, offset = 0.0, beats_per_bar=16, \n",
    "                    note_jump_speed=10, shuffle=0, shuffle_period=0.5, version=\"1.5.0\"):\n",
    "    new_beatmap = {}\n",
    "    new_beatmap['_version'] = version\n",
    "    new_beatmap['_beatsPerMinute'] = bpm\n",
    "    new_beatmap['_beatsPerBar'] = beats_per_bar\n",
    "    new_beatmap['_noteJumpSpeed'] = note_jump_speed\n",
    "    new_beatmap['_shuffle'] = shuffle\n",
    "    new_beatmap['_shufflePeriod'] = shuffle_period\n",
    "    new_beatmap['_events'] = []\n",
    "    new_beatmap['_notes'] = []\n",
    "    new_beatmap['_obstacles'] = []\n",
    "\n",
    "    \n",
    "    new_beatmap['_notes'] = [\n",
    "        {\n",
    "            \"_time\" : (i  / chunks_per_beat) + offset,\n",
    "            \"_lineIndex\" : k,\n",
    "            \"_lineLayer\" : j,\n",
    "            \"_type\" : original_beatmap[i][j][k][0] - 1,\n",
    "            \"_cutDirection\" : original_beatmap[i][j][k][1] - 1\n",
    "        } for i in range(original_beatmap.shape[0])\n",
    "          for j in range(original_beatmap.shape[1])\n",
    "          for k in range(original_beatmap.shape[2]) if original_beatmap[i][j][k][0] != 0]\n",
    "    \n",
    "    return new_beatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_beatmap(nn_output, tempo, filename = 'beatmap.json', \n",
    "                   division = 4, chunks_per_beat = 8, offset = 0.0,\n",
    "                   beats_per_bar=16, note_jump_speed=10,\n",
    "                   shuffle=0, shuffle_period=0.5, version=\"1.5.0\"):\n",
    "    \n",
    "    resized_map = convert_beatmap_array(nn_output, division)\n",
    "    converted_map = np.apply_along_axis(softmax_to_max, 3, resized_array)\n",
    "    json_beatmap = convert_to_json(converted_map, tempo, chunks_per_beat, \n",
    "                                   offset, beats_per_bar, note_jump_speed, \n",
    "                                   shuffle, shuffle_period, version)\n",
    "\n",
    "    with open(filename, 'w') as outfile:\n",
    "        outfile.write(json.dumps(json_beatmap, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_chunk = 300\n",
    "num_chunks_per_slice = 65\n",
    "num_chunks_per_beat = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/scipy/fftpack/basic.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n"
     ]
    }
   ],
   "source": [
    "X, Y, tempo  = data_prep([\"song.ogg\"], [\"Expert.json\"]) #\"song.ogg\"], [\"Expert.json\", \"Expert.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zube magic happens here\n",
    "# But, for now, we just use te original matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have issues where the net is predicting 'no note' for everything,\n",
    "# I think we should try adding a sensitivity parameter and call a\n",
    "# function here that lowers the softmax  value for all 'no note' predictions\n",
    "# by some amount, giving the others a higher chance of being the max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16\n"
     ]
    }
   ],
   "source": [
    "export_beatmap(Y, tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
